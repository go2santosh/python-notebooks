{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including TensorFlow, Keras, and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Import other required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Dataset\n",
    "Load the mini_pix2pix dataset from the data folder and preprocess the images for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Dataset\n",
    "\n",
    "# Define the path to the dataset\n",
    "data_path = 'data/mini_pix2pix/train'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((256, 256))  # Resize images to 256x256\n",
    "    image = np.array(image) / 127.5 - 1  # Normalize images to [-1, 1]\n",
    "    return image\n",
    "\n",
    "# Load the dataset\n",
    "input_images = []\n",
    "target_images = []\n",
    "\n",
    "for image_name in os.listdir(data_path):\n",
    "    if 'input' in image_name:\n",
    "        input_images.append(load_image(os.path.join(data_path, image_name)))\n",
    "    elif 'target' in image_name:\n",
    "        target_images.append(load_image(os.path.join(data_path, image_name)))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "input_images = np.array(input_images)\n",
    "target_images = np.array(target_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Generator Model\n",
    "Define the architecture of the generator model using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator Model\n",
    "def build_generator():\n",
    "    inputs = layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "    # Encoder\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same', use_bias=False)(inputs)\n",
    "    down1 = layers.BatchNormalization()(down1)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "\n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same', use_bias=False)(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "\n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same', use_bias=False)(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "\n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "\n",
    "    down5 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down4)\n",
    "    down5 = layers.BatchNormalization()(down5)\n",
    "    down5 = layers.LeakyReLU()(down5)\n",
    "\n",
    "    down6 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down5)\n",
    "    down6 = layers.BatchNormalization()(down6)\n",
    "    down6 = layers.LeakyReLU()(down6)\n",
    "\n",
    "    down7 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down6)\n",
    "    down7 = layers.BatchNormalization()(down7)\n",
    "    down7 = layers.LeakyReLU()(down7)\n",
    "\n",
    "    down8 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down7)\n",
    "    down8 = layers.BatchNormalization()(down8)\n",
    "    down8 = layers.LeakyReLU()(down8)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same', use_bias=False)(down8)\n",
    "    up1 = layers.BatchNormalization()(up1)\n",
    "    up1 = layers.Dropout(0.5)(up1)\n",
    "    up1 = layers.ReLU()(up1)\n",
    "    up1 = layers.Concatenate()([up1, down7])\n",
    "\n",
    "    up2 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same', use_bias=False)(up1)\n",
    "    up2 = layers.BatchNormalization()(up2)\n",
    "    up2 = layers.Dropout(0.5)(up2)\n",
    "    up2 = layers.ReLU()(up2)\n",
    "    up2 = layers.Concatenate()([up2, down6])\n",
    "\n",
    "    up3 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same', use_bias=False)(up2)\n",
    "    up3 = layers.BatchNormalization()(up3)\n",
    "    up3 = layers.Dropout(0.5)(up3)\n",
    "    up3 = layers.ReLU()(up3)\n",
    "    up3 = layers.Concatenate()([up3, down5])\n",
    "\n",
    "    up4 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same', use_bias=False)(up3)\n",
    "    up4 = layers.BatchNormalization()(up4)\n",
    "    up4 = layers.ReLU()(up4)\n",
    "    up4 = layers.Concatenate()([up4, down4])\n",
    "\n",
    "    up5 = layers.Conv2DTranspose(256, (4, 4), strides=2, padding='same', use_bias=False)(up4)\n",
    "    up5 = layers.BatchNormalization()(up5)\n",
    "    up5 = layers.ReLU()(up5)\n",
    "    up5 = layers.Concatenate()([up5, down3])\n",
    "\n",
    "    up6 = layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', use_bias=False)(up5)\n",
    "    up6 = layers.BatchNormalization()(up6)\n",
    "    up6 = layers.ReLU()(up6)\n",
    "    up6 = layers.Concatenate()([up6, down2])\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', use_bias=False)(up6)\n",
    "    up7 = layers.BatchNormalization()(up7)\n",
    "    up7 = layers.ReLU()(up7)\n",
    "    up7 = layers.Concatenate()([up7, down1])\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(3, (4, 4), strides=2, padding='same', use_bias=False)(up7)\n",
    "    outputs = layers.Activation('tanh')(up8)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Instantiate the generator model\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Discriminator Model\n",
    "Define the architecture of the discriminator model using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator Model\n",
    "def build_discriminator():\n",
    "    input_image = layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    target_image = layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "    # Concatenate the input and the target images\n",
    "    x = layers.Concatenate()([input_image, target_image])\n",
    "\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same', use_bias=False)(x)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "\n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same', use_bias=False)(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "\n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same', use_bias=False)(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "\n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=1, padding='same', use_bias=False)(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "\n",
    "    down5 = layers.Conv2D(512, (4, 4), strides=2, padding='same', use_bias=False)(down4)\n",
    "    down5 = layers.BatchNormalization()(down5)\n",
    "    down5 = layers.LeakyReLU()(down5)\n",
    "\n",
    "    down6 = layers.Conv2D(512, (4, 4), strides=1, padding='same', use_bias=False)(down5)\n",
    "    down6 = layers.BatchNormalization()(down6)\n",
    "    down6 = layers.LeakyReLU()(down6)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, (4, 4), strides=1, padding='same')(down6)\n",
    "\n",
    "    return Model(inputs=[input_image, target_image], outputs=outputs)\n",
    "\n",
    "# Instantiate the discriminator model\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the GAN Model\n",
    "Combine the generator and discriminator models to define the GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN Model\n",
    "def define_gan(generator, discriminator):\n",
    "    # Make the discriminator not trainable when combined with the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Define the input for the GAN model\n",
    "    input_image = layers.Input(shape=[256, 256, 3])\n",
    "    target_image = layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "    # Generate the fake image using the generator\n",
    "    generated_image = generator(input_image)\n",
    "\n",
    "    # Get the discriminator's output for the fake image\n",
    "    gan_output = discriminator([input_image, generated_image])\n",
    "\n",
    "    # Define the GAN model\n",
    "    gan = Model(inputs=[input_image, target_image], outputs=[gan_output, generated_image])\n",
    "\n",
    "    return gan\n",
    "\n",
    "# Instantiate the GAN model\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train the Models\n",
    "Compile the models and train the GAN using the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train the Models\n",
    "\n",
    "# Compile the discriminator model\n",
    "discriminator.compile(optimizer=tf.keras.optimizers.Adam(2e-4, beta_1=0.5),\n",
    "                      loss='binary_crossentropy')\n",
    "\n",
    "# Compile the GAN model\n",
    "gan.compile(optimizer=tf.keras.optimizers.Adam(2e-4, beta_1=0.5),\n",
    "            loss=['binary_crossentropy', 'mae'],\n",
    "            loss_weights=[1, 100])\n",
    "\n",
    "# Define the training function\n",
    "def train_gan(generator, discriminator, gan, input_images, target_images, epochs=100, batch_size=1):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(input_images)):\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, len(input_images), batch_size)\n",
    "            real_input = input_images[idx]\n",
    "            real_target = target_images[idx]\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_target = generator.predict(real_input)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
    "            fake_labels = np.zeros((batch_size, 16, 16, 1))\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = discriminator.train_on_batch([real_input, real_target], real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch([real_input, fake_target], fake_labels)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = gan.train_on_batch([real_input, real_target], [real_labels, real_target])\n",
    "\n",
    "        # Print the progress\n",
    "        print(f'Epoch: {epoch+1}, D Loss: {d_loss}, G Loss: {g_loss}')\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, input_images, target_images, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Visualize Translated Images\n",
    "Use the trained generator model to generate translated images and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and Visualize Translated Images\n",
    "\n",
    "# Function to generate and visualize translated images\n",
    "def generate_and_visualize(generator, input_images, target_images, num_images=5):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        # Select a random image from the dataset\n",
    "        idx = np.random.randint(0, len(input_images))\n",
    "        input_image = input_images[idx]\n",
    "        target_image = target_images[idx]\n",
    "\n",
    "        # Generate the translated image\n",
    "        translated_image = generator.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "        # Plot the input image\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow((input_image + 1) / 2)  # Convert back to [0, 1] range for display\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot the target image\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow((target_image + 1) / 2)  # Convert back to [0, 1] range for display\n",
    "        plt.title('Target Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot the translated image\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow((translated_image + 1) / 2)  # Convert back to [0, 1] range for display\n",
    "        plt.title('Translated Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize translated images\n",
    "generate_and_visualize(generator, input_images, target_images, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

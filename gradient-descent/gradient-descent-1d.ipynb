{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent in 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "def fx(x):\n",
    "    return 3*x**2 - 3*x + 4\n",
    "\n",
    "# Define derivative of the function\n",
    "def deriv_fx(x):\n",
    "    return 6*x - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the function and its derivative\n",
    "\n",
    "# Define range for x\n",
    "x = np.linspace(-1, 2, 2001)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x, fx(x), x, deriv_fx(x))\n",
    "plt.xlim(x[[0, -1]])\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend(['y', 'dy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning by gradient descent\n",
    "\n",
    "# Random starting point\n",
    "local_minima = np.random.choice(x, 1)\n",
    "\n",
    "# Learning parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "\n",
    "# Training\n",
    "for i in range(training_epochs):\n",
    "    gradient = deriv_fx(local_minima)\n",
    "    local_minima = local_minima - learning_rate * gradient\n",
    "\n",
    "local_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(x, fx(x), x, deriv_fx(x))\n",
    "plt.plot(local_minima, deriv_fx(local_minima), 'ro')\n",
    "plt.plot(local_minima, fx(local_minima), 'ro')\n",
    "\n",
    "plt.xlim(x[[0, -1]])\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend(['f(x)', 'df', 'f(x) min'])\n",
    "plt.title('Empirical local minimum: %s'%local_minima)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the learning steps\n",
    "\n",
    "# Random starting point\n",
    "local_minima = np.random.choice(x, 1)[0]  # Extract the scalar value\n",
    "\n",
    "# Learning parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "\n",
    "# Training steps while storing results\n",
    "model_params = np.zeros((training_epochs, 2))\n",
    "for i in range(training_epochs):\n",
    "    gradient = deriv_fx(local_minima)\n",
    "    local_minima = local_minima - learning_rate * gradient\n",
    "    model_params[i, :] = [local_minima, gradient]  # Use a list to match the shape\n",
    "\n",
    "local_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the gradient over iterations\n",
    "\n",
    "fix, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for i in range(2):\n",
    "    ax[i].plot(model_params[:, i], 'o-')\n",
    "    ax[i].set_xlabel('Iteration')\n",
    "    ax[i].set_title(f'Final estimated minima: {local_minima:.5f}')\n",
    "\n",
    "ax[0].set_ylabel('Local mimima')\n",
    "ax[1].set_ylabel('Derivative')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

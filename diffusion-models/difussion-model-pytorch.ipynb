{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Models from Scratch using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_swiss_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(size):\n",
    "    x, _ = make_swiss_roll(size)\n",
    "    return x[:, [2, 0]] / 10.0 * np.array([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, N=40, data_dim=2, hidden_dim=64):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.network_head = nn.Sequential(nn.Linear(data_dim, hidden_dim), nn.ReLU(),\n",
    "                                          nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), )\n",
    "        self.network_tail = nn.ModuleList([nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n",
    "                                                         nn.ReLU(), nn.Linear(hidden_dim, data_dim * 2)\n",
    "                                                         ) for _ in range(N)])\n",
    "\n",
    "    def forward(self, x, t: int):\n",
    "        h = self.network_head(x)\n",
    "        return self.network_tail[t](h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model: nn.Module, n_steps=40, device='cpu'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        betas = torch.linspace(-18, 10, n_steps)\n",
    "        self.beta = torch.sigmoid(betas) * (3e-1 - 1e-5) + 1e-5\n",
    "\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.n_steps = n_steps\n",
    "        self.sigma2 = self.beta\n",
    "\n",
    "    def forward_process(self, x0, t):\n",
    "\n",
    "        t = t - 1  # Start indexing at 0\n",
    "        beta_forward = self.beta[t]\n",
    "        alpha_forward = self.alpha[t]\n",
    "        alpha_cum_forward = self.alpha_bar[t]\n",
    "        xt = x0 * torch.sqrt(alpha_cum_forward) + torch.randn_like(x0) * torch.sqrt(1. - alpha_cum_forward)\n",
    "        # Retrieved from https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models/blob/master/model.py#L203\n",
    "        mu1_scl = torch.sqrt(alpha_cum_forward / alpha_forward)\n",
    "        mu2_scl = 1. / torch.sqrt(alpha_forward)\n",
    "        cov1 = 1. - alpha_cum_forward / alpha_forward\n",
    "        cov2 = beta_forward / alpha_forward\n",
    "        lam = 1. / cov1 + 1. / cov2\n",
    "        mu = (x0 * mu1_scl / cov1 + xt * mu2_scl / cov2) / lam\n",
    "        sigma = torch.sqrt(1. / lam)\n",
    "        return mu, sigma, xt\n",
    "\n",
    "    def reverse(self, xt, t):\n",
    "\n",
    "        t = t - 1  # Start indexing at 0\n",
    "        if t == 0: return None, None, xt\n",
    "        mu, h = self.model(xt, t).chunk(2, dim=1)\n",
    "        sigma = torch.sqrt(torch.exp(h))\n",
    "        samples = mu + torch.randn_like(xt) * sigma\n",
    "        return mu, sigma, samples\n",
    "\n",
    "    def sample(self, size, device):\n",
    "        noise = torch.randn((size, 2)).to(device)\n",
    "        samples = [noise]\n",
    "        for t in range(self.n_steps):\n",
    "            _, _, x = self.reverse(samples[-1], self.n_steps - t - 1 + 1)\n",
    "            samples.append(x)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x0 = sample_batch(5000)\n",
    "    x20 = model.forward_process(torch.from_numpy(x0).to(device), 20)[-1].data.cpu().numpy()\n",
    "    x40 = model.forward_process(torch.from_numpy(x0).to(device), 40)[-1].data.cpu().numpy()\n",
    "    data = [x0, x20, x40]\n",
    "    for i, t in enumerate([0, 20, 39]):\n",
    "        plt.subplot(2, 3, 1 + i)\n",
    "        plt.scatter(data[i][:, 0], data[i][:, 1], alpha=.1, s=1)\n",
    "        plt.xlim([-2, 2])\n",
    "        plt.ylim([-2, 2])\n",
    "        plt.gca().set_aspect('equal')\n",
    "        if t == 0: plt.ylabel(r'$q(\\mathbf{x}^{(0...T)})$', fontsize=17, rotation=0, labelpad=60)\n",
    "        if i == 0: plt.title(r'$t=0$', fontsize=17)\n",
    "        if i == 1: plt.title(r'$t=\\frac{T}{2}$', fontsize=17)\n",
    "        if i == 2: plt.title(r'$t=T$', fontsize=17)\n",
    "\n",
    "    samples = model.sample(5000, device)\n",
    "    for i, t in enumerate([0, 20, 40]):\n",
    "        plt.subplot(2, 3, 4 + i)\n",
    "        plt.scatter(samples[40 - t][:, 0].data.cpu().numpy(), samples[40 - t][:, 1].data.cpu().numpy(),\n",
    "                    alpha=.1, s=1, c='r')\n",
    "        plt.xlim([-2, 2])\n",
    "        plt.ylim([-2, 2])\n",
    "        plt.gca().set_aspect('equal')\n",
    "        if t == 0: plt.ylabel(r'$p(\\mathbf{x}^{(0...T)})$', fontsize=17, rotation=0, labelpad=60)\n",
    "    plt.savefig(f\"Imgs/diffusion_model.png\", bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, nb_epochs=150_000, batch_size=64_000):\n",
    "    training_loss = []\n",
    "    for _ in tqdm(range(nb_epochs)):\n",
    "        x0 = torch.from_numpy(sample_batch(batch_size)).float().to(device)\n",
    "        t = np.random.randint(2, 40 + 1)\n",
    "        mu_posterior, sigma_posterior, xt = model.forward_process(x0, t)\n",
    "        mu, sigma, _ = model.reverse(xt, t)\n",
    "\n",
    "        KL = (torch.log(sigma) - torch.log(sigma_posterior) + (sigma_posterior ** 2 + (mu_posterior - mu) ** 2) / (\n",
    "                2 * sigma ** 2) - 0.5)\n",
    "        loss = KL.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLP(hidden_dim=128).to(device)\n",
    "model = DiffusionModel(model_mlp)\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=1e-4)\n",
    "train(model, optimizer)\n",
    "plot(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

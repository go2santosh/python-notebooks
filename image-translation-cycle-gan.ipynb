{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpaired Image-to-Image Translation using Cycle-GAN\n",
    "\n",
    "Download horse2zebra dataset from https://efrosgans.eecs.berkeley.edu/cyclegan/datasets/horse2zebra.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the horse2zebra dataset\n",
    "PATH = 'data/horse2zebra'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def load_image(filename):\n",
    "    image = load_img(filename, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    image = img_to_array(image)\n",
    "    image = (image / 127.5) - 1.0  # Normalize the image to [-1, 1] range\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_file):\n",
    "    image = load_image(image_file)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(path):\n",
    "    return [os.path.join(path, fname) for fname in os.listdir(path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_files = load_image_files(PATH + '/trainA/')\n",
    "zebra_files = load_image_files(PATH + '/trainB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses = tf.data.Dataset.from_tensor_slices(horse_files).map(lambda x: tf.numpy_function(preprocess_image, [x], tf.float32)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_zebras = tf.data.Dataset.from_tensor_slices(zebra_files).map(lambda x: tf.numpy_function(preprocess_image, [x], tf.float32)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CycleGAN model\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(BatchNormalization())\n",
    "    result.add(LeakyReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(BatchNormalization())\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "    result.add(LeakyReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "    ]\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4),\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4),\n",
    "    ]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh')\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    skips = reversed(skips[:-1])\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = last(x)\n",
    "    return Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='target_image')\n",
    "    x = Concatenate()([inp, tar])\n",
    "    down1 = downsample(64, 4, False)(x)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\n",
    "    conv = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)\n",
    "    batchnorm1 = BatchNormalization()(conv)\n",
    "    leaky_relu = LeakyReLU()(batchnorm1)\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "    last = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)\n",
    "    return Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g = Generator()\n",
    "generator_f = Generator()\n",
    "discriminator_x = Discriminator()\n",
    "discriminator_y = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "LAMBDA = 10\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "discriminator_x_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "        same_x = generator_f(real_x, training=True)\n",
    "        same_y = generator_g(real_y, training=True)\n",
    "        disc_real_x = discriminator_x([real_x, real_y], training=True)\n",
    "        disc_real_y = discriminator_y([real_y, real_x], training=True)\n",
    "        disc_fake_x = discriminator_x([real_x, fake_y], training=True)\n",
    "        disc_fake_y = discriminator_y([real_y, fake_x], training=True)\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "        generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
    "        generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
    "        discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
    "        discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
    "        generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "        generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
    "        discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "        discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 19:34:06.936452: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:00:33.218346: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 completed\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    for image_x, image_y in tf.data.Dataset.zip((train_horses, train_zebras)):\n",
    "        train_step(image_x, image_y)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Translated Image']\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_horse = next(iter(train_horses.take(1)))\n",
    "sample_zebra = next(iter(train_zebras.take(1)))\n",
    "generate_images(generator_g, sample_horse)\n",
    "generate_images(generator_f, sample_zebra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
